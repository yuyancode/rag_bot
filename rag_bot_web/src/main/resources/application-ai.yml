langchain4j:
  community:
    dashscope:
      tokenizer:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: qwen-plus
      # LLM
      chat-model:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: qwen-plus
        temperature: 0.7
      # Streaming LLM
      streaming-chat-model:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: qwen-plus
        temperature: 0.7
      # Embedding model
      embedding-model:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: text-embedding-v3
        dimensions: 1024


# Embedding model - PgVector
pgvector:
  database: vecdb
  host: ${SERVER_IP}
  port: 5432
  user: postgres
  password: wcw985211
  table: vectors_db

# search engine
search:
  engine: google
  api-key: ${SEARCH_ENGINE_API}

# personal LLM
llm:
  apikey: ${DEEPSEEK_API_KEY}
  model: deepseek-reasoner
  baseUrl: https://api.deepseek.com


# 对话配置
chat:
  context:
    compress-min-interval-minutes: 5                 # 压缩的最小间隔（分钟）
    window-size: 10                                  # 上下文保留轮数
    expire-hours: 168                                # 上下文过期时间（小时，24*7=168）
    compression-token-threshold: 5000                # 触发压缩的最大 token 阈值

coze:
  token: ${COZE_TOKEN}